{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting text from multi-column pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: nltk in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (4.22.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: tqdm in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (1.22.3)\n",
      "Requirement already satisfied: torchvision in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from sentence-transformers) (0.13.1)\n",
      "Requirement already satisfied: filelock in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: joblib in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
      "Requirement already satisfied: networkx in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (2.8.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence-transformers\n",
    "!pip3 install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: joblib in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (from nltk) (2022.9.13)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in /home/akshat/miniconda3/envs/mindmaps/lib/python3.10/site-packages (1.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/akshat/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/akshat/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/akshat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/akshat/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "DIGITIZED_FILE = \"Psychology.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            identifier = \"{0}_{1}_{2}_{3}\".format(s['size'], s['flags'], s['font'], s['color'])\n",
    "                            styles[identifier] = {'size': s['size'], 'flags': s['flags'], 'font': s['font'],\n",
    "                                                  'color': s['color']}\n",
    "                        else:\n",
    "                            identifier = \"{0}\".format(s['size'])\n",
    "                            styles[identifier] = {'size': s['size'], 'font': s['font']}\n",
    "\n",
    "                        font_counts[identifier] = font_counts.get(identifier, 0) + 1  # count the fonts usage\n",
    "\n",
    "    font_counts = sorted(font_counts.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    if len(font_counts) < 1:\n",
    "        raise ValueError(\"Zero discriminating fonts found!\")\n",
    "\n",
    "    return font_counts, styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_tags(font_counts, styles):\n",
    "    \"\"\"Returns dictionary with font sizes as keys and tags as value.\n",
    "    :param font_counts: (font_size, count) for all fonts occuring in document\n",
    "    :type font_counts: list\n",
    "    :param styles: all styles found in the document\n",
    "    :type styles: dict\n",
    "    :rtype: dict\n",
    "    :return: all element tags based on font-sizes\n",
    "    \"\"\"\n",
    "    p_style = styles[font_counts[0][0]]  # get style for most used font by count (paragraph)\n",
    "    p_size = p_style['size']  # get the paragraph's size\n",
    "\n",
    "    # sorting the font sizes high to low, so that we can append the right integer to each tag \n",
    "    font_sizes = []\n",
    "    for (font_size, count) in font_counts:\n",
    "        font_sizes.append(float(font_size))\n",
    "    font_sizes.sort(reverse=True)\n",
    "\n",
    "    # aggregating the tags for each font size\n",
    "    idx = 0\n",
    "    size_tag = {}\n",
    "    for size in font_sizes:\n",
    "        idx += 1\n",
    "        if size == p_size:\n",
    "            idx = 0\n",
    "            size_tag[size] = '<p>'\n",
    "        if size > p_size:\n",
    "            size_tag[size] = '<h{0}>'.format(idx)\n",
    "        elif size < p_size:\n",
    "            size_tag[size] = '<s{0}>'.format(idx)\n",
    "\n",
    "    return size_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headers_para(doc, size_tag):\n",
    "    \"\"\"Scrapes headers & paragraphs from PDF and return texts with element tags.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param size_tag: textual element tags for each size\n",
    "    :type size_tag: dict\n",
    "    :rtype: list\n",
    "    :return: texts with pre-prended element tags\n",
    "    \"\"\"\n",
    "    header_para = []  # list with headers and paragraphs\n",
    "    first = True  # boolean operator for first header\n",
    "    previous_s = {}  # previous span\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # this block contains text\n",
    "\n",
    "                # REMEMBER: multiple fonts and sizes are possible IN one block\n",
    "\n",
    "                block_string = \"\"  # text found in block\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if s['text'].strip():  # removing whitespaces:\n",
    "                            if first:\n",
    "                                previous_s = s\n",
    "                                first = False\n",
    "                                block_string = size_tag[s['size']] + s['text']\n",
    "                            else:\n",
    "                                if s['size'] == previous_s['size']:\n",
    "\n",
    "                                    if block_string and all((c == \"|\") for c in block_string):\n",
    "                                        # block_string only contains pipes\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    if block_string == \"\":\n",
    "                                        # new block has started, so append size tag\n",
    "                                        block_string = size_tag[s['size']] + s['text']\n",
    "                                    else:  # in the same block, so concatenate strings\n",
    "                                        block_string += \" \" + s['text']\n",
    "\n",
    "                                else:\n",
    "                                    header_para.append(block_string)\n",
    "                                    block_string = size_tag[s['size']] + s['text']\n",
    "\n",
    "                                previous_s = s\n",
    "\n",
    "                    # new block started, indicating with a pipe\n",
    "                    # block_string += \"|\"\n",
    "\n",
    "                header_para.append(block_string)\n",
    "\n",
    "    return header_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(DIGITIZED_FILE)\n",
    "font_style, styles = fonts(doc)\n",
    "size_tag = font_tags(font_style, styles)\n",
    "headers_para = headers_para(doc, size_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = []\n",
    "paragraphs = []\n",
    "for text in headers_para:\n",
    "    if text.startswith(\"<h\"):\n",
    "        headings.append(text[3:])\n",
    "    elif text.startswith(\"<s\"):\n",
    "        pass\n",
    "    else:\n",
    "        if text.endswith(\"|\"):\n",
    "            paragraphs.append(text[3:-1])\n",
    "        else:\n",
    "            paragraphs.append(text[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    " \n",
    "class LemmatizerHelper(object):\n",
    "    \"\"\"\n",
    "    Class to aid the lemmatization process - from word to stemmed form,\n",
    "    and vice versa.\n",
    "    The 'original' form of a lemmatized word will be returned as the\n",
    "    form in which its been used the most number of times in the text.\n",
    "    \"\"\"\n",
    " \n",
    "    #This reverse lookup will remember the original forms of the lemmatized\n",
    "    #words\n",
    "    word_lookup = {}\n",
    " \n",
    "    @classmethod\n",
    "    def lemmatize(cls, sentence):\n",
    "        \"\"\"\n",
    "        Lemmatize a sentence and updates the reverse lookup.\n",
    "        \"\"\"\n",
    " \n",
    "        #Lemmatize the word\n",
    "        lemmatized = cls.lemmatize_sentence(sentence)\n",
    " \n",
    "        return lemmatized\n",
    "\n",
    "    @classmethod\n",
    "    def nltk_pos_tagger(cls, nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:          \n",
    "            return None\n",
    "\n",
    "    @classmethod\n",
    "    def lemmatize_sentence(cls, sentence):\n",
    "\n",
    "        nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "        wordnet_tagged = map(lambda x: (x[0], cls.nltk_pos_tagger(x[1])), nltk_tagged)\n",
    "        lemmatized_sentence = []\n",
    "        \n",
    "        for word, tag in wordnet_tagged:\n",
    "            if tag is None:\n",
    "                lemmatized_sentence.append(word)\n",
    "            else:        \n",
    "                lemmatized_sentence.append(wnl.lemmatize(word, tag))\n",
    "        return \" \".join(lemmatized_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rotman Research Institute at Baycrest , Toronto , Ontario , Canada', 'In real-life decision situation we be often face with alterna- tives that seem so equivalent that choice be extremely difficult . Under such circumstance our final selection may feel like an arbitrary choice , although in fact there may be implicit influence act outside conscious control that bias us toward select one alternative over another . The observation that people can make correct choice while believe that they be select randomly have a long history in experimental psychology . Studies date from the 19th century have consistently find that participant can make subtle perceptual discrimination judgment with above- chance accuracy despite claim that they be simply guess ( Adams , 1957 ; Voss & Paller , 2010 ) . Voss and colleague have recently provide evidence for a similar effect in recognition memory ( Voss , Baym & Paller , 2008 ) . Participants study a series of kaleidoscope image and then attempt to recognize the stud- ied item among a set of perceptually similar pair . The study', 'phase be perform under either full attention ( FA ) or divide attention ( DA ) condition , and the recognition test be either a yes-no test ( 10 study target mixed with 10 similar foil ) or a 2-AFC test ( 10 simultaneously present target-foil pair ) . In the yes-no test , recognition accuracy be good follow encode under FA condition but very poor follow DA at encode , as one might expect in an explicit memory situation . Surprisingly , however , participant ’ performance on the forced-choice test be well follow DA than FA at encode . Further experiment reveal that when participant be ask to rate their forced- choice response as be on the basis of some memory for the studied item or as random guess , recognition accuracy be high for response judge to be guess than for those think to be base on memory . These experiment thus provide evidence for substantial level of recognition memory when participant believe they be simply guessing—that be , for recognition without awareness . This result be obtain only under very specific condition , however—when encoding be perform under DA condition , when the test be 2-AFC , when respond be under a tight time deadline ( c. 2 sec from stimulus onset ) , and when the choice be between two perceptually similar visual pattern . There be essentially no ev- idence for the effect with a yes-no testing procedure or even with a forced-choice procedure when participant be give unlimited time to respond or when target stimulus be pair with a percep- tually dissimilar foil ( Voss et al. , 2008 , Experiments 3 & 4 , respectively ) . A subsequent study reveal a further limitation ; the effect be not obtain in the forced-choice procedure when participant be encourage to respond accurately and guess only when absolutely necessary , although the original result reappear when participant be encourage to guess ( Voss & Paller , 2010 ) . Voss and colleague refer to their finding as “ implicit recogni- tion ” and suggest that the underlying process be different both', 'from those mediate explicit recollection and from those medi- ating feeling of familiarity . They comment that “ Familiarity- base recognition be take as an instance of explicit memory because familiarity response entail the awareness of memory retrieval ” ( Voss et al. , 2008 , p. 458 ) . In support of the claim that implicit recognition have a different mechanism they cite a further study ( Voss & Paller , 2009 ) in which participant perform the forced-choice test for kaleidoscope pattern , encode under either FA or DA condition . Participants in this study assess each recognition choice as be associate with some explicit recol- lection of the encode phase ( “ remember ” � R ) , with a more general feeling of familiarity ( they simply “ knew ” it have be study � K ) , or as a pure guess . Event-related potential ( ERP ) recording be also make during the recognition test . The result confirm early finding of high level of accuracy follow DA at encode , and also of great than chance accuracy level with “ guess ” response , especially in the DA condition . Addition- ally , the pattern of behavioral result in guess decision be distinct from the pattern observe with both R and K decision , suggest that the mechanism associate with implicit recognition be different from that associate with recognition with awareness . The ERP result support this claim . Recognition responses ac- companied by feeling of recollection or familiarity be associ- ated with positive shift in the late positive complex ( 600–900 m ) and in the P200 potential . In contrast , correct guess response be associate with frontal-occipital negative potential occur 200–400 m after stimulus onset . The author speculate that the distinct mechanism underlie the phenomenon of recognition without awareness may reflect a stimulus-specific enhancement of perceptual fluency ( e.g. , Jacoby & Whitehouse , 1989 ) , with this subtle change in process yield enough information to sup- port a correct recognition choice , although not enough to give rise to any conscious feeling of remember . A major question arise from this work be whether the phe- nomenon of recognition without awareness can be demonstrate with material other than complex perceptual pattern and , if so , whether it be associate with similar neural mechanism . Is implicit recognition find with verbal material , for example ? In one early experiment , Peynirciog˘lu ( 1990 ) have participant study a list of word , and then give them a word-fragment completion test in which some fragment be from the list and others be new . Participants attempt to complete the fragment and also rat each fragment with regard to whether it be base on a list member or base on a new word . Considering only fragment that be not complete , a high mean rating be give to list than lure word . Thus , apparently participant have some sense of fa- miliarity for the fragment even in the absence of identification . Subsequent work by Cleary and Greene ( 2004 , 2005 ) show that when study and unstudied word be present too quickly to identify in a perceptual identification test , participant could still discriminate study from unstudied item . The author attribute the effect to a great sense of familiarity associate with the briefly flash studied word . The finding that recognition without identification be associate with a specific ERP signal ( Voss & Paller , 2009 ) be confirm and extend to verbal material in a study use the method of Peynirciog˘lu ( 1990 ) and report by Ryals , Yadon , Nomi , and Cleary ( 2011 ) . The two major finding be , first , that for unidentified word fragment the proportion attribute to the original list be great for studied than unstudied', 'unidentified item ; that be , recognition without identification ( RWI ) be again obtain . Second , the ERP correlate of the RWI effect be an N300 component of the evoked response , in agree- ment with Voss and Paller ( 2009 ) but use verbal material and a yes-no recognition procedure . Ryals and colleague conclude that their result confirm the existence of unconscious recognition memory and that the RWI effect be index by the N300 ERP signature . A study by Starns , Hicks , Brown , and Martin ( 2008 ) also find evidence for recognition without identification use verbal mate- rial . Their basic paradigm be to have participant study a list of word in which half of the word be print in large font and half in small font ( Experiment 1 ) , or be rat for either pleas- antness or imageability ( Experiments 2 & 3 ) . Participants be then give a recognition list compose of 50 % study word and 50 % lure ; additionally , half of the participant be inform that only 25 % be target and the other half inform that 75 % be target . Following this test , participant be re-presented with the original list and ask to decide the “ source ” —that be , whether each word have be in small or large font ( or rat for pleasantness or imageability ) . The major finding be that participant ’ source judgment be above chance for word they have fail to recog- nize in the first test . Importantly , however , this effect be find only in the condition in which participant be inform that only 25 % of the test word be target . The author conclude that the phenomenon of accurate source memory for unrecognized item be a reality , but that it occur only under condition in which a conservative response bias have be induce . In summary , there be good evidence for the phenomenon of recognition without awareness , although the evidence associate with verbal material be somewhat indirect in the sense that correct decision about list membership be make on the basis of word fragment or the word themselves present very briefly ( Cleary and colleague ) . Similarly , in the experiment by Starns et al . ( 2008 ) the evidence for recognition without identification come from above-chance attribution of source rather than of the word themselves . One interest question then be whether the phenom- enon would extend to condition in which participant correctly select word present in full view despite claim that they be simply guess . This be the question address in the present experiment . We become interested in these finding when consider the result of an early set of experiment report by Gopie , Craik and Hasher ( 2011 ) . In that study , young and old adult partic- ipants first name the print color ( red , green , blue , yellow ) of a series of word as rapidly as possible ; they be inform that the word themselves be irrelevant . This encode phase be fol- low by a word fragment completion test , contain fragment of word from the “ encode ” list as well as new word fragment . The high completion rate for repeat word than for new word ( prim effect ) be great for old adult ( 0.25 ) than for young adult ( 0.10 ) , in line with the notion that old adult fail to inhibit “ irrelevant ” information , which they can subsequently use if that information become useful ( Hasher , Zacks & May , 1999 ) . Surprisingly , however , this pattern reverse in a second experiment use the same color-naming initial phase , but with explicit instruction to “ use word from the initial list where possible ” in the fragment-completion test . Now young adult have a prim score of 0.24 and old adult ’ score drop to 0.08 .', 'The same Age � Implicit/Explicit interaction be replicate in a further experiment . What be the nature of the encoded verbal information in the incidental color-naming situation ? It be well establish that im- plicit verbal test such as fragment completion be particularly sensitive to perceptual information ( e.g. , Craik , Moscovitch & McDowd , 1994 ; Schacter , Dobbins , & Schnyer , 2004 ) , and the successful prim show by old adult suggest that they may have encode word in the color-naming phase in a perceptual manner . When young adult perform the color-naming task under DA condition , their subsequent fragment-completion per- formance resemble that of old adult ( implicit completion � 0.22 , explicit completion � � .03 ; Gopie et al. , 2011 , Experiment 3 ) , again suggest that the DA condition induce a somewhat superficial encoding of the word . This DA condition obviously resemble the DA condition use by Voss and colleague , and the finding of successful fragment completion subsequent to this type of encode fit well with Voss and colleague ’ characterization of their recognition without awareness as reflect enhance percep- tual fluency . These initial finding prompt the question of whether recognition without awareness would be observe if the color-naming initial phase be follow by an explicit recognition test . Would participant select a previously view word at great than chance level while claim that they be simply guess ? The follow- ing experiment investigate this possibility . A further purpose of the present series of study be to obtain more information about the type of representation associate with implicit recognition , and the factor that affect the size of the effect . The similarity and difference between effect obtain with word and with kaleidoscope pattern should suggest com- monalities and limitation among the various representation un- derlying implicit recognition effect . The result may also point to difference in the representation associate with implicit and explicit memory for the studied item . Do such difference reflect the involvement of different memory system , for example ( e.g. , Tulving & Schacter , 1990 ) , or simply difference in the type or amount of information the representation contain about the orig- inal episode ( e.g. , Chechile , Sloboda & Chamberland , 2012 ) ? With regard to factor that might influence the size of the effect , we be influence by two finding from previous study and one conjecture of our own . First , we present word in an initial encode phase under either full or divided attention condition ( FA or DA ) . The reason for this follow the strong effect observe by Voss and colleague under DA condition , also the possibility from the study by Gopie et al . ( 2011 ) that DA induce a more superficial perceptual encoding . We speculate that recog- nition without awareness for word might also be strong follow- ing such condition . Second , the result of Starns et al . ( 2008 ) provide strong evidence that the effect would be great under condition of conservative responding in the test phase , so our result be examine with this point in mind . Finally , in line with the notion of encode specificity ( Tulving & Thomson , 1973 ) we hypothesize that the effect would be strong to the extent that the encoding and test condition be different , so this factor be also incorporate in our design . The rationale for this last point be describe in the next paragraph . To illustrate the phenomenon of recognition failure of recallable word , Tulving and Thomson ( 1973 ) first present target word as response item in a paired-associate list . Next , in an apparently', 'unrelated phase of the experiment , participant be give cue word and ask to generate four free association to each cue word . The cue be choose so that the generated association often match response word in the previous paired-associate list . In the third phase , participant be ask to read through the word they have generate and circle any they recognize as the previously learn word . Finally , they be give the original paired-associate stimulus word as cue to recall the appropriate response . The main result be that participant often fail to recognize generated target word in Phase 3 , although the same word be recall in response to the original paired-associate cue in the final phase . The author ’ interpretation of this striking result be that target word encode specifically as response in a paired-associate list be not perceive subjectively as the same word when encounter again as their own generate associa- tions . Essentially , the context change between encode and test act to reduce recognition . Applying this thinking to the phe- nomenon of recognition without awareness , our conjecture be that a similar change of context between initial encoding and the recognition test might result in a failure of explicit recog- nition , but allow the participant to still select the correct target word in a forced-choice test by virtue of implicit recognition . This notion predict that great amount of context change between encode and test would be associate with increased recognition failure but also an increase likelihood of ‘ recog- nition without awareness. ’ In order to provide a sensitive test of recognition memory , and to allow for the possibility of recognition without awareness , we use the testing procedure devise by Tulving and Thomson . In the present study , participant be show a series of 4-word set and instruct to choose the one word they may have encounter in the first ( encode ) phase . They be also tell ( correctly ) that some of the 4-word set contain no target , but that they must still select one word as the most likely to have be in the first phase . To make sense of this procedure , participant be also instruct to give a confidence rating for each choice , in which 2 � “ fairly certain it be on the list , ” 1 � “ possibly on the list , ” and 0 � “ pure guess—I be force to choose one. ” In a 4-AFC situation , chance responding will yield p � .25 , so the interest in the present experiment be in case in which target item be present , partici- pant give a rating of 0 , yet choose correctly at a level high than 0.25 . In line with the previous literature , we will refer to such outcome as ‘ recognition without awareness. ’ Experiments 1 and 2 utilize the color-naming procedure report by Gopie et al . ( 2011 ) as the encode phase , and in the final two experiment we use the paired-associate learning task report by Tulving and Thomson ( 1973 ) .', 'Participants . The participant be 48 undergraduate from the University of Toronto who participate in the experiment for course credit . Their mean age be 18.9 year , and mean score on the Shipley vocabulary scale ( Zachary , 1986 ) be 29.1 . Partici- pant be randomly assign to the FA or DA condition , n � 24 per condition .', 'Design and procedure . The experiment consist of two phase ; incidental encoding follow by a 4-AFC recognition test . These phase be separate by a 10-min retention interval in which participant play the Tetris computer game . The first phase be describe as a color-judgment experiment , in which participant be present with a series of 40 common noun whose font color be red , blue , green or yellow . The task be to judge the color of each word as it appear in the computer monitor and to respond as rapidly as possible by press one of four response button . Following each response there be a 1,000 m intertrial interval before the next word appear . The word themselves be describe as be irrelevant to the task . Half of the participant perform the task under FA condition , and half under DA condition . The DA task be to listen to a string of auditory digit present at a 1.5 s rate , and detect target define as three successive odd digit ( e.g. , 7–9–5 , 1–3–1 , etc. ) . DA participant signal detection of an auditory target by press the space bar . After complete the color-judgment task , all 48 participant play the computer game Tetris for 10 min . They then all per- form an explicit recognition memory task under full attention condition . The recognition test contain 50 4-AFC trial ; partic- ipants be instruct to select one of the four word in all cases—a word that may have be an ignored color word in the first phase . Of the 50 trial , 40 do contain one target word from the study phase , and 10 contain no target word . Participants be inform that on certain trial no target word would be present , but that they should always choose the word they judge to be the most likely from Phase 1 . Participants be also ask to rate their choice as a word they be “ fairly certain ” have be in Phase 1 , as “ possibly there ” or as a “ pure guess. ” These rating be cod as 2 , 1 , and 0 , respectively .', 'When a target word be present among the four choice , par- ticipants rat their choice as a “ pure guess ” on an average of 19.1 trial out of 40 ( 48 % ) in the FA condition and 20.9 trial ( 52 % ) in the DA condition . In these case the proportion of correct choice be 0.27 and 0.33 for FA and DA condition , respectively ; that be , the proportion of correct selection be 0.27 and 0.33 , give that a target word be present and that the selection be make with zero confidence . The proportion of “ pure guess ” judgment in this and the following experiment be give in Table 1 under the heading “ Prop . 0. ” The value of correct selection give a con- fidence rating of zero be refer to as p ( c ) |0 , and these value be also give in Table 1 . The chance value be 0.25 , and t test show that the 0.27 value be not significantly different from 0.25 , t ( 23 ) � 0.80 , p � .05 , whereas the value of 0.33 be reliably different from chance , t ( 23 ) � 4.82 , p � .001 . Additionally , the DA value of 0.33 be significantly high than the FA value of 0.27 , t ( 46 ) � 2.11 , p � .05 . When a target be present in the set , the conditional probability of choose it correctly give a con- fidence rating of 1 ( “ possibly there ” ) or 2 ( “ fairly certain ” ) be 0.35 and 0.49 , respectively , for FA participant , and 0.32 and 0.43 , respectively , for DA participant . Thus performance be above chance but far from perfect when participant claim some mem- ory awareness of their choice .', 'The major finding of interest be that participant in the DA condition do exhibit some degree of recognition without aware- ness . In that condition , 18 participant have value of correct choice rat as a “ guess ” that exceed the chance level of 0.25 whereas only four participant have value less than 0.25 . The finding of more recognition without awareness follow DA condition at encode echoes the finding of Voss and colleague , and be in line with the idea that this encode condition may have yield superficial perceptual encoding of word . Arguably , this type of encoding may be sufficient to choose target word cor- rectly in a late forced-choice recognition test , but insufficient to yield the subjective experience of remember . In order to obtain further evidence on this phenomenon we replicate the study in a second experiment , but with the one difference that participant be inform in the first color-judging phase that memory for the word would be test later . Our assumption be that this change would result in more deliberate encoding of the word , and there- fore an increase in hit rate in the recognition test . We also pre- dicted that this strong encode would be associate with a decline in the proportion of “ 0 ” response ( because of the in- creased hit rate ) and a reduction in the propensity to select target word while apparently guess ( follow our assumption that intentional encoding in the first phase would result in a great match between encode and retrieval ) .', 'The design and procedure be exactly as in Experiment 1 , include the FA and DA condition , but with the one alteration that participant be inform before perform the color- judgment task that there would be a memory test for the colored word . The participant be again undergraduate who partici- pat for course credit ; 24 be test in the FA condition ( mean age � 19.0 year ; Shipley vocabulary � 29.5 ) and 21 be test', 'Table 1 Performance Measures in Experiments 1 -- 4', 'in the DA condition ( mean age � 19.3 year ; Shipley vocabu- lary � 30.1 ) .', 'When a target word be present , participant rat their choice as a “ pure guess ” 10.5 time , on average , out of a possible 40 trial in the FA condition and 15.2 time , on average , in the DA condition . Thus the measure of proportion “ 0 ” be 0.26 and 0.39 , respectively ( see Table 1 ) . In these “ pure guess ” case , the mean proportion of correct choice be 0.39 in the FA condition and 0.30 in the DA condition ( see Table 1 ) . Although both of these p ( c ) |0 value exceed the chance value of 0.25 , only the FA value be significantly high than 0.25 , t ( 23 ) � 2.85 , p � .01 ; the DA value be not significantly great than chance , t ( 20 ) � 1.56 , p � .05 . In addition , the FA value of 0.39 be not significantly high than the DA value of 0.30 , t ( 43 ) � 1.54 , p � .05 . The proportion of correct selection make with confidence rating 1 and 2 when target be present be 0.44 and 0.84 , respectively for the FA condition , and 0.31 and 0.57 , respectively for the DA condition . These “ aware ” value be understandably high than the corre- sponding value in Experiment 1 . Three 2 ( FA/DA ) � 2 ( Experiments 1 & 2 ) analysis of variance ( ANOVAs ) be also carry out to compare the value of hit rate , proportion “ 0 ” and p ( c ) |0 between the experiment . Hit rate be define as the probability of select the correct target when one be present , regardless of confidence rating . The ANOVA on hit rate show a significant effect of experiment , F ( 1 , 90 ) � 42.12 , p � .001 , �', '� .32 , of FA/DA , F ( 1 , 90 ) � 33.47 , p � .001 , �', '� 0.27 , and the interaction between the two factor , F ( 1 , 90 ) � 32.02 , p � .001 , �', '� .26 . Table 1 indicate that these effect show that hit rate in Experiment 2 be generally high than those in Experiment 1 , and also that hit rate be high for FA than DA condition . However , these effect be modulate by a significant interaction between the factor ; only the FA condition in Experi- ment 2 show the benefit of intentional learning condition . The ANOVA on proportion “ 0 ” score reveal significant effect of experiment , F ( 1 , 90 ) � 21.06 , p � .001 , �', '� .19 , and of FA/DA , F ( 1 , 90 ) � 4.78 , p � .03 , �', '� .05 , but no interaction , F ( 1 , 90 ) � 1.11 , p � .05 . That be , value of proportion “ 0 ” be high for Experiment 1 than for Experiment 2 , and somewhat high for DA condition than for FA condition ( see Table 1 ) . The ANOVA on p ( c ) |0 value show that neither the effect of Experiment , F ( 1 , 90 ) � 1.68 , p � .05 nor FA/DA ( F � 1.0 ) be significant , but the interaction be statistically reliable , F ( 1 , 89 ) � 5.58 , p � .02 , �', '� .06 . Table 1 show that this last effect be attributable to the value for DA be high than that for FA in Experiment 1 , but that FA be great than DA in Experiment 2 .', 'Our prediction for Experiment 2 relative to the first experiment be that the intentional learning instruction in the color- judgment phase would increase the hit rate , reduce the proportion of “ 0 ” confidence rating , and also reduce the value of proportion correct , give a “ 0 ” rating [ p ( c ) |0 ] . The first two prediction be bear out by the result , although the hit rate increase be find only for FA condition . The prediction that p ( c ) |0 would decrease be not upheld , however . There be no main effect for experi-', 'ment , but the significant interaction between Experiment and FA/DA show that p ( c ) |0 increase from 0.27 to 0.39 in the FA condition but decline slightly ( from 0.33 to 0.30 ) in the DA condition . The speculation that recognition without awareness might decrease as a function of a good match between encode and test condition be , therefore , not support by these result . Our assumption be that the intentional encoding instruction in Experiment 2 would be more similar than the incidental condition in Experiment 1 to the intentional recognition condition at test , and so p ( c ) |0 should decline from Experiment 1 to Experiment 2 , which generally do not happen . Another initial prediction be that the probability of recognition without awareness would be great in DA than in FA condition . This prediction be support marginally in Experiment 1 , but the probability of p ( c ) |0 reverse in Experiment 2 where the value be 0.39 for FA and 0.30 for DA . The difference be not significant , but be nevertheless in the wrong direction . The proportion of guess response do drop substantially as the poten- tial to learn the word in Phase 1 increase . In turn , this result raise the possibility that the subjective meaning of a guess re- sponse might change as a function of how well word be learn . The possibility that such a change in criterion might signal a shift to more conservative responding in line with the conclu- sion of Starns et al . ( 2008 ) be consider again after describe two further experiment . Despite obtain result from the two color-word experiment that give little support to the notion of either context change or encode under DA condition as a basis for recognition without awareness , we decide to change the encode paradigm before abandon the idea . Accordingly , we run two experiment use a paradigm that be close to the paradigm use by Tulving and Thomson ( 1973 ) . One difference be that in our version the test word be provide rather than generate by the participant . The paradigm thus consist of several paired associate list in the encoding phase follow by a test phase consisting of a series of 4-AFC recognition test . To encourage the use of the “ pure guess ” ( “ 0 ” ) response , only half of the test trial contain a target , and participant be inform of this fact . Experiment 3 be the first study use this paradigm , and so be basically exploratory in nature .', 'Experiment 3 again contain an encode phase follow by a test phase . In this case the first phase consist of a series of paired-associate list , and this phase be follow by a 4-AFC recognition test for word on the final list . The participant be 48 young adult ( undergraduate student ) who be allocate ran- domly to one of two condition , FA and DA , during the learning phase . The FA condition have 24 participant ( mean age � 18.8 year ; year of education � 12.3 ) and the DA condition also have 24 participant ( mean age � 18.6 year ; year of education � 12.5 ) . The material use for the paired-associate list be com- mon word ( mostly nouns ) of 1–3 syllable and range in fre- quency from 10 ( coin ) to 1,207 ( man ) accord to the Kucˇera and Francis ( 1967 ) norm . During the encode phase , participant study two list of 24 paired associate ( Lists 1 & 2 ) present', 'visually at a 5 s rate with a 1 s interstimulus interval . Participants in the DA condition also perform the “ successive-odd-digits ” task present auditorily while learn the list . In this case the DA task be make slightly easy by ask participant to detect the presence of two successive odd digit . At the end of each list all participant complete a self-paced cued-recall test . List 3 have 48 pair associate present in the same way , but at the end of presentation participant be inform that we be interested in the effect of time delay on memory , and that the recall test would come later . In the meantime , they play the computer game Tetris for 5 min . Participants be then give 48 set of four word on two sheet of paper . Half of the set contain a response word from List 3 ; the other half contain no target word . There be two version of the 4-AFC recognition test ( A & B ) ; 24 participant ( 12 FA and 12 DA ) receive Version A , which contain 24 List 3 response word , and the remain 24 participant receive Version B , which contain the target word not on A . Participants be ask to circle one word in each set of four , the word most likely to come from List 3 . They be inform that only half of the 4-word set contain a target , but they should always select one , guess when necessary . They be also instruct to provide a confidence rating with each word , with 0 , 1 , 2 have the same meaning as in Experiments 1 and 2 . Finally , they be give the cued-recall test for the original List 3 .', 'Paired associate recall probability be 0.36 , 0.61 and 0.43 for Lists 1 , 2 , 3 , respectively , for the FA group , and 0.12 , 0.36 , and 0.26 , respectively , for the DA group . Thus , as expect , the recall value for DA participant be consistently low than the cor- responding value for FA participant . As show in Table 1 , hit rate be 0.69 and 0.57 for the FA and DA group , respectively . Thus intentional learning of paired- associate response present at a relatively slow rate ( 6 s per pair ) be associate with high hit rate than those obtain from the first two experiment . Proportions of target word recognize correctly with confidence rating 1 and 2 be 0.58 and 0.94 , respectively , for the FA group , and 0.55 and 0.79 , respectively , for the DA group . All of these value be reliably high than 0.25 , all value of t � 6.50 . Table 1 also show that the proportion of word select with zero confidence on the 24 trial when a target word be present be 0.26 for FA participant and 0.31 for DA participant . When a target word be present and the selection be make with zero confidence , participant be correct with propor- tions 0.40 for the FA group and 0.34 for the DA group . These value be show in Table 1 under the heading p ( c ) |0 . The 0.40 value for FA be great than the chance value of 0.25 , t ( 22 ) � 2.73 , p � .01 ; but the 0.34 value for DA be not reliably great than chance , t ( 23 ) � 1.60 , p � .12 . From the point of view of the context change hypothesis , it be unclear whether the shift between paired-associate learning and the 4-AFC test be more or less than the shift between color-word naming and the test , so the final experiment be design to provide a clear test of this hypoth- esis . For now it may be note that the value of p ( c ) |0 be again high for the FA group than for the DA group , again provide no evidence for the notion that recognition without awareness be associate with DA at encode . The third hypothesis , that the', 'incidence of recognition without awareness be restrict to condi- tions of conservative responding ( Starns et al. , 2008 ) , be difficult to assess from these data ; consideration of this possibility be defer until the final experiment be describe . The major purpose of Experiment 4 be to provide a strong test of the context shift account by make condition for the 4-AFC test as compatible as possible with the encode condition . This be accomplish by remind participant of the original paired- associate pair at the time of the recognition test . We do this by precede each set of four word in the 4-AFC test with a stimulus word from the original learned list . When a target word be present in the set it be always precede by its correct stimulus word from the original List 3 learn trial . Thus , if the original pair to be learn be moth-FOOD , the four word provide for the recognition test ( BASE , FOOD , BOOK , FARM ) would be precede by “ moth. ” When a target word be not present , the recognition set be compose of four new word precede by a randomly chosen stimulus word from the original paired-associate list . By reinstate the learn context in this way we expect to increase the hit rate but greatly reduce the phenomenon of recog- nition without awareness .', 'Experiment 4 be a replication of Experiment 3 , with the one change that each set of four word in the 4-AFC recognition test be precede by a stimulus word from the 48 pair to be learn in List 3 . In the 24 case that a target word be present , the stimulus word be its correct pair mate ; the remain 24 4-AFC case ( which contain no target word ) be pair randomly with the remain 24 stimulus word . As in Experiment 3 , half of the participant be give the A set of 4-AFC choice and half be give Set B. Forty-eight participant age 18–28 year par- ticipated in the study . Half of them be assign to the FA condition ( mean age � 21.8 year , mean year of education � 14.8 ) and half to the DA condition ( mean age � 21.3 year , mean year of education � 14.8 ) . The DA group again perform the auditory monitoring task ( “ tap the table every time you hear 2 successive odd digit ” ) while learn the initial three paired- associate list .', 'The overall recognition performance in this cued 4-AFC situa- tion be predictably high—85 % correct for FA and 84 % correct for DA participant ( hit rate in Table 1 ) . Nevertheless , partici- pant do rate their confidence level as zero in a number of instance when a target be present ; the proportion be 0.17 for the FA group and 0.15 for the DA group ( proportion “ 0 ” in Table 1 ) . For the 21 participant in the FA group who select item with zero confidence , the proportion of correct choice be 0.41 ; this value be significantly great than the chance value of 0.25 , t ( 20 ) � 3.31 , p � .01 . For the 18 DA participant who select item with zero confidence , the proportion be 0.43 , and the associate significance value be t ( 17 ) � 3.38 , p � .01 . Clearly these value of p ( c ) |0 do not fall close to 0.25 as predict , and be broadly comparable to the result of Experiment 3 , despite the', 'apparent success of the contextual reinstatement manipulation— overall recognition rate rise from 69 % to 85 % for FA participant in Experiments 3 and 4 , respectively , and from 57 % to 84 % , respectively , for DA participant . Other result make sense in light of the easy condition asso- ciated with the cue 4-AFC procedure . Probabilities of correct recognition give confidence rating 1 and 2 be 0.60 and 0.99 , respectively , for FA participant , and 0.61 and 0.99 , respectively , for DA participant . Cued recall probability for Lists 1 , 2 , and 3 be 0.43 , 0.62 , and 0.54 , respectively , for FA participant , and 0.20 , 0.44 , and 0.44 , respectively , for DA participant . Thus the DA manipulation reduce recall value , as in the previous exper- iments , but it be interest to note that the manipulation do not reduce recognition score in this instance . Apparently , the combi- nation of context reinstatement with the forced-choice procedure be sufficient to compensate for the poorer initial encode re- vealed in the cued recall case . Three ANOVAs be conduct to compare the result of Experiments 3 and 4 . Each be a 2 ( Experiments 3 & 4 ) � 2 ( FA vs. DA ) between subject analysis . For overall hit rate , there be a significant effect of Experiment , F ( 1 , 92 ) � 44.70 , p � .001 , �', '� .33 , and marginally reliable effect of FA/DA , F ( 1 , 92 ) � 3.23 , p � .08 , �', '� .03 , and the interaction between the factor , F ( 1 , 92 ) � 2.90 , p � .10 , �', '� .03 . Table 1 show that these effect signify that hit rate be high in Experiment 4 than in Experiment 3 , and that there be a trend for these value to be high for FA than for DA , especially in Experiment 3 . For the measure proportion “ 0 , ” the ANOVA yield a significant effect of Experiment , F ( 1 , 92 ) � 14.91 , p � .001 , �', '� .14 , but no effect of either FA/DA ( F � 1.0 ) or of the interaction , F ( 1 , 92 ) � 1.79 , ns . Table 1 show that the proportion of zero response be great in Experiment 3 than in Experiment 4 . For the measure p ( c ) |0 , the effect of Experiment be not significant , F ( 1 , 82 ) � 2.63 , p � .05 , and neither the effect of FA/DA ( F � 1.08 ) nor the interaction ( F � 1.0 ) approach significance . But the major result of interest be that the great amount of contextual reinstatement from Experiment 3 to Experiment 4 have no effect on the value of p ( c ) |0 . The contextual reinstatement manipulation clearly work , give the substantially high level of overall recognition in the present experiment , but there be no evidence for a reduction in ‘ recognition without awareness. ’ The hypothesis that recognition without awareness in these paradigm might be akin to the phenomenon of recognition failure in the Tulving and Thomson ( 1973 ) experiment be therefore not sup- port by the present result , or at least not in the version that propose that the size of the effect should be reduce as the encoding and retrieval context be make more similar . Over the four experiment , there be thus little or no support for either the context change hypothesis or the notion that recognition without awareness be more likely to occur under condition of DA at encode . The remain hypothesis , that the value of p ( c ) |0 rise as recognition decision be make under more conservative crite- ria , be consider in the General Discussion that follow .', 'A consideration of the data from all four experiment ( see Table 1 ) show clearly that our measure of recognition without aware- ness [ p ( c ) |0 ] do not vary systematically with FA/DA at encod-', 'ing , and there be also little evidence for the notion that p ( c ) |0 varies as a function of context shift between encode and retrieval . However , another possibility stem from the idea that there may be criterion shift in the likelihood of give a zero confidence re- sponse . In particular , it seem possible that the criterion may depend on the overall ease or difficulty of the final 4-AFC recog- nition test . Presumably easy task will yield many 1 and 2 judg- ments when target be present , and relatively few 0 judgment . But for easy task , target be typically rather obvious and will be rat 1 or 2 . If an item be less obvious , it may be choose but give a zero confidence rating when contrast with easy item . This thinking predict a relationship between overall difficulty of the recognition test and value of p ( c ) |0—easy task should give relatively few “ 0 ” judgment , but a high value of p ( c ) |0 .', 'Table 1 show that the overall hit rate rise generally from Experiment 1 to Experiment 4 , indicate that there be a tendency for the task to become easy . The Table also show a tendency for the proportion of “ 0 ” response when a target be present to decline from the first to the last experiment ( understandably , as participant make more confident 1 or 2 response as task diffi- culty decrease ) and also for the measure p ( c ) |0 to increase from Experiments 1 to 4 . These trend be assess by carry out a series of Spearman ’ s rho correlation coefficient among the vari- ables , use the mean of the eight condition ( 4 Experiments � FA/DA ) . The correlation between hit rate and proportion “ 0 ” be rho ( 6 ) � � 0.94 , p � .01 and the correlation between hit rate and p ( c ) |0 be rho ( 6 ) � � 0.93 , p � .01 ( Figure 1a and 1b , respec- tively ) . Additionally , the correlation between proportion “ 0 ” and p ( c ) |0 be rho ( 6 ) � � 0.91 , p � .01 . There be thus good evidence across the eight condition that as the task become easy ( mea- sured by increase hit rate ) , the proportion of “ 0 ” confidence response decline and the value of p ( c ) |0 correspondingly in- crease . Also , it be the case that value of p ( c ) |0 increase system- atically as the proportion of “ 0 ” response decline . Further insight into the process operate in the experiment may be gain by consider the relation between hit rate and the proportion of response give 1 or 2 rating when a target be present , and also between hit rate and the proportion of these 1 or 2 response that be actually correct [ p ( c ) |1 � 2 ] . The pro- portion give either 1 or 2 confidence response be simply the complement of the proportion give zero response , and be show in column 4 of Table 1 . These value signal the occasion that participant think they have choose the correct item . In order to compare the value of proportion correct give 1 or 2 [ p ( c ) |1 � 2 ] with the proportion choose with 1 or 2 confidence rating , we correct value of p ( c ) |1 � 2 for chance . Specifically , for each condition we first calculate the proportion correct give a rating of 1 or 2 ; we then subtract the chance value of 0.25 from that proportion , and divide the result by 1.0 minus chance ( 0.75 ) . The result scale of proportion correct give a 1 or 2 rating thus run from 0 to 1.0 , as do the scale of proportion of 1 or 2 chosen . The corrected value of p ( c ) |1 � 2 be show in column 5 of Table 1 . These value , and also the proportion of 1 or 2 chosen , be plot against overall hit rate in Figure 2 . The figure show that both function be well fit by linear function , but with different slope . At low value of hit rate ( difficult task ) the proportion correct be around 0.15–0.20 , whereas the proportion of selection make with1 or 2 confidence rating be between 0.45 and 0.55 . That be , the relatively high', 'confidence level be unwarranted by the proportion actually correct . This discrepancy reduce , however , as the task get easy , until at high level of hit rate ( relatively easy task ) the propor- tions of choice make with 1 or 2 rating be slightly low than the corresponding proportion correct . That be , participant be some- what conservative in their allocation of confidence rating at the easy end of task difficulty . This observation be in line with previous report that stricter criterion be typically apply to strongly en- coded stimulus and thus easy detection and recognition perfor- mance ( Singer , 2009 ) . On the assumption that trials themselves vary on a continuum of difficulty for each person in a give experiment , this pattern imply that for low value of hit rate participant allocate more rating of 1 and 2 than they “ ought to ” give the difficulty level , so the remain “ 0 ” allocation be give to the most difficult trial , and correspondingly show a low probability of be correct . When hit rate be high , however , the pattern reverse . Now participants allocate few rating of 1 and 2 to choice than they might do give the relatively easy task , and so the remain “ 0 ” allocation be give to trial that be also', 'relatively easy and so show a high hit rate . In summary , we suggest that the strong correlation between overall hit rate and p ( c ) |0 be a function of a change criterion for the allocation of “ 0 ” response ( Singer , 2009 ) . The probability of ‘ recognition without awareness ’ increase as the task become easy , and participant adopt a more conservative criterion for claim that they have choose an item from the encode list . How general be this criterion account of recognition without awareness ? It be clearly compatible with the result of Starns and colleague ( 2008 ) who explicitly conclude that source memory for unrecognized item vary with the bias to respond “ old ” in recognition decision . In their case the phenomenon appear only under condition that promote conservative responding . The pres- ent account be probably less applicable to the study by Cleary and Greene ( 2004 , 2005 ) and by Ryals et al . ( 2011 ) who show recognition of list membership in the absence of identification on the basis of process word fragment or speed processing of the word themselves . In these case the recognition of list mem- bership be probably due to an unconscious recognition memory process , possibly attributable to a minimal sense of familiarity as the author suggest . With regard to the study of Voss and colleague ( Voss et al. , 2008 ; Voss & Paller , 2009 , 2010 ) , we agree with those author that the term “ implicit memory ” should be reserve for case in which individual ’ performance show evidence of memory for previous event , yet they be unaware that their response be base on memory . By this definition , choice accompany by feeling of either recollection or familiarity ( or give with either “ remember ” or “ know ” response ) be classify as case of explicit memory . On the contrary , correct choice make but classify as ‘ guess ’ be instance of implicit memory—recognition without awareness . Such instance be document both by Voss and colleague and in the present experiment .', 'Voss and Paller ( 2010 ) consider , but reject , the possibility that recognition without awareness be simply base on the processing of relatively weak representation that might otherwise evoke response of familiarity or recollection ( see also Voss , Lucas & Paller , 2012 ) . Their argument be base partly on different ERP signature relate to implicit memory compare to those associ- ated with familiarity and recollection ( Voss et al. , 2012 ) , but also to the change in R , K , and guess response between condition in', 'which guessing be either encourage or discourage . In the latter case , the probability of a guess response be accurate be p � .43 ( less than chance in a 2-AFC paradigm ) , whereas when guess- ing be encourage the accuracy of response classify as guess rise to p � .78 ( Voss & Paller , 2010 ) . Interestingly , the propor- tions correct for R and K response do not change systematically between the two encouragement condition : for R responses the proportion correct be 0.80 under “ confidence encourage ” in- structions and 0.76 under “ guess encourage “ instruction ; the corresponding proportion for K response be 0.60 and 0.62 , respectively . The author argue that this result be not consistent with a simple shift in criterion . However , an alternative reading of the result be that whereas the encouragement to guess lead to an increase in the rate of guess ( from 12 % to 26 % ) and a con- comitant decrease in the rate for R and K response , the subjective criterion for K and R response ( base on proportion correct ) remain relatively unchanged , whereas the encouragement to use the “ guess ” response allow participant to select that response more often . It be also necessary to add that the subjective criterion for “ guess ” must have change , such that under encourage condition item that might otherwise be classify as K or R be now classify more cautiously as guess , with a consequent rise in the probability that such response be correct . Our suggestion be therefore that encouragement to guess differentially change the criterion for what constitute a ‘ guess ’ response but leave the subjective label unchanged for K and R response . Conditions under which recognition without awareness be not observe in the study report by Voss and colleague include recognition of kaleidoscope pattern use a yes-no procedure , use a 2-AFC procedure when the two choice be perceptually very different , and when participant be give an extended time to decide . All of these case likely engender a deliberate conscious retrieval strategy rather than a reliance on perceptually base implicit recognition . Voss and Paller ( 2009 ) boost their case for a perceptual basis of their implicit memory demonstration by show- ing that the neural correlate of the effect include frontal-occipital brain potential at 200–400 ms post-stimulus-onset , potential that be distinct from the late positive response associate with judgment of recollection or familiarity . Given that these research- er use complex and relatively meaningless kaleidoscope pattern as stimulus it make sense that recognition choice be make on the basis of perceptual processing . In our own case the stimulus be word , the four choice present on each test trial be not perceptually similar , and participant perform the sequence of 4-AFC test trial at their own pace , rather than under time pressure . In addition , Table 1 make it clear that there be no systematic change associate with encode under full versus divide attention in our experi- ments . It thus seem clear that implicit recognition can occur with a variety of material and under a variety of experimental condi- tions . One way of reconcile the present result with those of Voss and Paller be to suggest that the selection of a correct item be base on process the relevant neural representation in all case , although of course the nature of that representation will vary widely . We also suggest that such representation be the basis for correct selection for both implicit and explicit recognition mem- ory ; the difference between the two type be that explicit memory be accompany additionally by some representation of the context of initial occurrence—either a nonspecific feeling of past occur-', 'rence in the case of K response or specific recollection of context for R response . Speculatively , this second type of representation may be associate with change in the neural activation record as the late positive complex in the ERP signal report by Voss and Paller ( 2009 ) . In turn , various factor will contribute to the encoding and retrieval of such contextual representation ; they may include such thing as attention to contextual attribute during encode , the associative relationship of the target item to its initial context , the degree to which the retrieval context match the encode context , and the extent to which the participant engage deliberate attempt to recollect the initial situation . These , of course , be among the factor study by many researcher inves- tigating the characteristic of explicit recollection . The point we wish to stress here be that two distinct set of factor may be operate to give rise to the phenomenon of recognition without awareness ; one set contribute to the relative strength ( or degree of fluent processing ) of representation of target item and their lure , the second set contributes to the occurrence and adequacy of representation of the initial encode context of these target item . According to this view , recognition without awareness will occur when item representation be strongly present ( or be process fluently ) , but contextual repre- sentations be weak or absent . In the Voss and Paller experiment , participant deliberately attempt to learn the kaleidoscope pat- tern so good item representation be establish . It seem likely , however , that the corresponding contextual representation be poorly differentiate among the various very similar item , enable participant to select a target item correctly but in the absence of any feeling of recollection that it be one they have study . The encoding of well-differentiated contextual represen- tations would be even less likely under divide attention condi- tions , and the retrieval of such representation would be poor under condition that discourage a deliberate analytic retrieval strategy— for example , the speeded 2-AFC condition use in the Voss and Paller study . In the case of the current experiment , participant be pre- sumably able to form good item representation under the inten- tional learning condition of Experiment 2 , 3 , and 4 . Context information be also available at encode but this information may have be difficult to access at retrieval give that the item be now present in a very different 4-AFC context . Addition- ally , we suggest that the probability of correctly select a target item with zero confidence vary with the overall difficulty of the particular recognition test , and a concurrent shift in the criterion associate with the subjective feeling of what constitute a “ guess ” response . Voss and Paller ( 2012 ) suggest that their effect be base on fluency of perceptual processing of the encoded repre- sentations , and this seem very reasonable give that the item be complex and relatively meaningless visual pattern . In the present case , the correct selection of the target word when confi- dence be zero may also be attributable to the great perceptual fluency of process target relative to lure ( Jacoby and White- house ( 1989 ) . Alternatively , Chechile , Sloboda , and Chamberland ( 2012 ) have suggest that implicit and explicit recognition differ simply in the adequacy ( e.g. , strength , vividness ) of the encoded representation , with weakly represent item be insufficient to support explicit recognition , but still sufficient to select the correct item while claim that the choice be simply a guess . We add to the Chechile et al . model by suggest that the criterion for a', '“ guess ” response be variable as describe earlier , but differ from them by suggest that explicit recognition also involve the retrieval of a further representation of the initial context .', 'The four experiment present in this article provide ample evidence for the reality of recognition without awareness ; in this case , with word expose for several second . In many way the existence of the phenomenon be unsurprising as related effect have be report over the year . One example be the ability of participant to make accurate psychophysical judgment ( e.g. , relative judgment of weight , length , and shape ) while claim that they be simply guess ( early study review by Adams , 1957 ) . A second example be evidence for semantic processing of word in the absence of conscious identification of these word ( e.g. , Marcel , 1983 ; Stenberg , Lindgren , Johansson , Olsson & Rosén , 2000 ) . In the present case we have suggest that variation in the strength of the effect be principally attributable to the general difficulty of the recognition decision in a particular experiment— easy decision be associate with few guess response but with high value of recognition without awareness [ high value of p ( c ) |0 ] . The data be thus consistent with the notion that the subjective criterion for choose correctly while state that the choice be simply a guess be flexible , depend ( among other possible factor ) on the context of the overall recognition situation . It may be ask what “ criterion shift ” mean across different condition that always involve the forced-choice procedure ; do the participant not simply choose the subjectively strong item in all case ? In answer , we emphasize that our use of the term “ criterion shift ” do not refer to whether or not participant make a choice—they choose on all trials—but rather to the subjective state accompany the selection , and to the fact that this state vary as a function of overall task difficulty . Under easy condi- tions many trial yield obvious selection label 1 or 2 . On the remain trial participant can still select the correct item , but these case feel relatively less obvious and be therefore labeled 0 . Under difficult condition participant make more “ guess ” selec- tions , but in this case the general difficulty result in the selection of few target item ; choice be much closer to chance respond . Finally , unlike Voss and Paller ( 2009 ) , we see no reason in our data to suggest that implicit and explicit recognition reflect differ- ent form of memory . We argue rather that correct selection of a target item may be base on relative fluency of processing , or on the strength or adequacy of its encoded representation , and that these factor be likely to vary on a continuum . Additionally , however , the recognition process will evoke some representation of the item ’ s previous context of occurrence . This representation will also vary in the degree to which it fully specify the past event ; inadequate representation may simply evoke a feeling of general “ pastness ” whereas more adequate representation will reinstate a conscious memory of the original event . In turn , these different degree of adequacy will be associate , respectively , with the subjective impression of familiarity and recollection . In case where such additional contextual representation be not evoke , the participant may still choose the target item correctly , but now with no subjective feeling of explicit recognition . These case may therefore be describe as recognition without awareness .', 'Received November 12 , 2014 Revision receive March 13 , 2015 Accepted March 17 , 2015 �', 'If you be interested in review manuscript for APA journal , the APA Publications and Communications Board would like to invite your participation . Manuscript reviewer be vital to the publication process . As a reviewer , you would gain valuable experience in publishing . The P & C Board be particularly interested in encourage member of underrepresented group to participate more in this process .', 'If you be interested in review manuscript , please write APA Journals at Reviewers @ apa.org . Please note the following important point :', '• To be select as a reviewer , you must have publish article in peer-reviewed journal . The experience of publish provide a reviewer with the basis for prepare a thorough , objective review .', '• To be select , it be critical to be a regular reader of the five to six empirical journal that be most central to the area or journal for which you would like to review . Current knowledge of recently publish research provide a reviewer with the knowledge base to evaluate a new submission within the context of exist research .', '• To select the appropriate reviewer for each manuscript , the editor need detailed information . Please include with your letter your vita . In the letter , please identify which APA journal ( s ) you be interested in , and describe your area of expertise . Be as specific as possible . For example , “ social psychology ” be not sufficient—you would need to specify “ social cognition ” or “ attitude change ” as well .', '• Reviewing a manuscript take time ( 1–4 hour per manuscript review ) . If you be select to review a manuscript , be prepare to invest the necessary time to evaluate the manuscript thoroughly .', 'APA now have an online video course that provide guidance in review manuscript . To learn more about the course and to access the video , visit http : //www.apa.org/pubs/authors/review- manuscript-ce-video.aspx .']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_paras = []\n",
    "for i in range(len(paragraphs)):\n",
    "    if paragraphs[i] != \"\":\n",
    "        lemmatized_paras.append(LemmatizerHelper.lemmatize(paragraphs[i]))\n",
    "print(lemmatized_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.parsing.preprocessing import remove_stopwords\n",
    "# word_list = []\n",
    "# for paragraph in stemmed_paras:\n",
    "#     if paragraph != '':\n",
    "#         filtered_sentence = remove_stopwords(paragraph)\n",
    "#         temp = filtered_sentence.split(\" \")\n",
    "#         word_list.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# min_count = 3\n",
    "# size = 100\n",
    "# window = 4\n",
    " \n",
    "# model = Word2Vec(word_list, min_count=min_count, vector_size=size, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_terms = list(model.wv.index_to_key)\n",
    "# key_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_key_terms = []\n",
    "# for i in key_terms:\n",
    "#     if len(i) >= 3:\n",
    "#         new_key_terms.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class KWE:\n",
    "    # text=\"\"\"Determining whether online users are authorized to access digital objects is central to preserving privacy. This pa- per presents the design, implementation, and deployment of Zanzibar, a global system for storing and evaluating ac- cess control lists. Zanzibar provides a uniform data model and configuration language for expressing a wide range of access control policies from hundreds of client services at Google, including Calendar, Cloud, Drive, Maps, Photos, and YouTube. Its authorization decisions respect causal or- dering of user actions and thus provide external consistency amid changes to access control lists and object contents. Zanzibar scales to trillions of access control lists and millions of authorization requests per second to support services used by billions of people. It has maintained 95th-percentile la- tency of less than 10 milliseconds and availability of greater than 99.999% over 3 years of production use.\"\"\"\n",
    "\n",
    "    def __init__(self,t):\n",
    "        self.text=t\n",
    "\n",
    "    def keywordExtract(self):\n",
    "        n_gram_range = (1, 1)\n",
    "        stop_words = \"english\"\n",
    "        count = CountVectorizer(ngram_range=n_gram_range,\n",
    "                                stop_words=stop_words).fit(self.text)\n",
    "\n",
    "        candidates = count.get_feature_names_out()\n",
    "        model = SentenceTransformer('all-mpnet-base-v2')\n",
    "        doc_embedding = model.encode(self.text)\n",
    "        candidate_embeddings = model.encode(candidates)\n",
    "\n",
    "        top_n = 25\n",
    "        distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "        keywords = [candidates[index] for index in distances.argsort()[0]][-top_n:]\n",
    "\n",
    "        return keywords, candidates, model\n",
    "    # keywrdextract(data)\n",
    "# if _name_ == \"_main_\":\n",
    "c = KWE(lemmatized_paras)\n",
    "keywords, candidates, model = c.keywordExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['address', 'phenom', 'experimental', 'studies', 'target', 'authors', 'mechanism', 'publication', 'ac', 'stem', 'central', 'paller', 'chamberland', 'institute', 'generated', 'rho', 'publications', 'experiments', 'research', 'researcher', 'canada', 'baycrest', 'ontario', 'toronto', 'rotman']\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from networkx import Graph\n",
    "\n",
    "def build_mind_map(nodes, model, candidates, root=\"experimental\", alpha=0.2):\n",
    "    g = Graph()\n",
    "\n",
    "    for node in nodes:\n",
    "        if node not in candidates:\n",
    "            raise ValueError(f\"Node {node} not in candidates\")\n",
    "    if root not in nodes:\n",
    "        raise ValueError(f\"Root {root} not in nodes\")\n",
    "\n",
    "    unvisited_nodes = set(nodes)\n",
    "\n",
    "    visited_nodes = set([])\n",
    "\n",
    "    visited_node_vectors = {}\n",
    "\n",
    "    node_distances = {}\n",
    "\n",
    "\n",
    "    current_node = root\n",
    "    visited_node_vectors[root]=model.encode([root])\n",
    "    unvisited_nodes.remove(root)\n",
    "    visited_nodes.add(root)\n",
    "\n",
    "    for i in range(1, len(nodes)):\n",
    "        for x in unvisited_nodes.copy():\n",
    "            dist_from_current = cosine_similarity(visited_node_vectors[root], model.encode([x]))\n",
    "            distance = node_distances.get(x, (100, ''))\n",
    "            if distance[0] > dist_from_current:\n",
    "                node_distances[x] = (dist_from_current, current_node)\n",
    "            \n",
    "            next_node = min(unvisited_nodes, key=lambda u: node_distances[x][0])\n",
    "\n",
    "            if next_node in node_distances.keys():\n",
    "                parent = node_distances[next_node][1]\n",
    "            else: \n",
    "                node_distances[next_node] = (cosine_similarity(visited_node_vectors[root], model.encode([next_node])), current_node)\n",
    "                parent = node_distances[next_node][1]\n",
    "            del node_distances[next_node]\n",
    "            next_node_vec = ((1 - alpha) * model.encode([next_node]) + alpha * visited_node_vectors[parent])\n",
    "\n",
    "            visited_node_vectors[next_node] = next_node_vec\n",
    "            unvisited_nodes.remove(next_node)\n",
    "\n",
    "            visited_nodes.add(next_node)\n",
    "\n",
    "            g.add_edge(parent, next_node)\n",
    "\n",
    "            current_node = next_node\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "mind_map = build_mind_map(nodes=keywords, model=model, candidates=candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 25 nodes and 24 edges\n"
     ]
    }
   ],
   "source": [
    "print(mind_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "Agraph = nx.nx_agraph.to_agraph(mind_map)\n",
    "Agraph.layout(prog=\"dot\")\n",
    "Agraph.draw(\"file.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mindmaps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dc3d65545c52fc3480745454bf9ad36b9e9094198317f42229a0b71dd4fc340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
